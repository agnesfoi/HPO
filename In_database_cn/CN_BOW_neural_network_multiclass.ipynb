{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
 ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import jieba\n",
    "import pandas as pd\n",
    "#import jieba.analyse\n",
    "\n",
    "os.chdir('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (done)/NLP_for_onedrive')\n",
    "#from NLP_function import *\n",
    "os.chdir('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (done)/NLP_for_onedrive/In_Database_cn') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df = pd.read_csv('C:/Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (done)/NLP_for_onedrive/Data_Prepare/Training_data_final.csv', encoding='ANSI')\n",
    "\n",
    "# remove class without information\n",
    "Df = Df.fillna('无')\n",
    "Df = Df[Df.y_cn!='无']\n",
    "Df = Df[Df.y_cn!='正常']\n",
    "Df = Df.drop_duplicates(subset='x_cn')\n",
    "\n",
    "# remove less informative class\n",
    "#Df = Df[Df.y_cn_count>=10]\n",
    "\n",
    "# change number\n",
    "Df['x_cn'] = Df['x_cn'].apply(lambda x : change_number(x,'cn'))\n",
    "\n",
    "# define X,Y for model learning\n",
    "X, Y  = Df['x_cn'], Df['y_cn']\n",
    "x_cut = X.apply(lambda txt: list(jieba.cut(txt))) #jieba tokenization\n",
    "x_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df = pd.read_csv('C:/Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (done)/NLP_for_onedrive/Data_Prepare/Training_data_final.csv', encoding='ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x_cn</th>\n",
       "      <th>y_cn</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag_class</th>\n",
       "      <th>check_group</th>\n",
       "      <th>change</th>\n",
       "      <th>y_cn_count</th>\n",
       "      <th>HP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4534</td>\n",
       "      <td>先天性单侧输精管缺如</td>\n",
       "      <td>1型糖尿病</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>HP:0100651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4535</td>\n",
       "      <td>非梗阻性无精症</td>\n",
       "      <td>1型糖尿病</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>HP:0100651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4536</td>\n",
       "      <td>无精症</td>\n",
       "      <td>1型糖尿病</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>HP:0100651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4537</td>\n",
       "      <td>胰岛素 - 依赖性糖尿病</td>\n",
       "      <td>1型糖尿病</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>HP:0100651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4538</td>\n",
       "      <td>全部卵异常 蜡样透明带 厚而致密 卵周无间隙</td>\n",
       "      <td>Abnormal zona pellucida morphology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>HP:0020156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    x_cn                                y_cn  tag  \\\n",
       "0   4534              先天性单侧输精管缺如                               1型糖尿病  NaN   \n",
       "1   4535                 非梗阻性无精症                               1型糖尿病  NaN   \n",
       "2   4536                     无精症                               1型糖尿病  NaN   \n",
       "3   4537            胰岛素 - 依赖性糖尿病                               1型糖尿病  NaN   \n",
       "4   4538  全部卵异常 蜡样透明带 厚而致密 卵周无间隙  Abnormal zona pellucida morphology  NaN   \n",
       "\n",
       "  tag_class  check_group  change  y_cn_count          HP  \n",
       "0       NaN          9.0     NaN           4  HP:0100651  \n",
       "1       NaN          9.0     NaN           4  HP:0100651  \n",
       "2       NaN          9.0     NaN           4  HP:0100651  \n",
       "3       NaN          9.0     NaN           4  HP:0100651  \n",
       "4       NaN          9.0     NaN           7  HP:0020156  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-54097c66ca53>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Df['x_cn'][0] = '先天性单侧输精管缺如'\n",
      "<ipython-input-7-54097c66ca53>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Df['x_cn'][1] = '非梗阻性无精症'\n",
      "<ipython-input-7-54097c66ca53>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Df['x_cn'][2] = '全部卵异常'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [先天, 天性, 先天性, 单侧, 输精, 缺如, 输精管, 输精管缺如]\n",
       "1                  [梗阻, 梗阻性, 无精症, 非梗阻性无精症]\n",
       "2                              [全部, 卵, 异常]\n",
       "Name: x_cn, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['x_cn'][0] = '先天性单侧输精管缺如'\n",
    "Df['x_cn'][1] = '非梗阻性无精症'\n",
    "Df['x_cn'][2] = '全部卵异常'\n",
    "\n",
    "X = Df['x_cn'].iloc[0:3,]\n",
    "x_cut = X.apply(lambda txt: list(jieba.cut_for_search(txt))) #jieba tokenization\n",
    "x_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [先天性/n, 单侧/n, 输精管缺如/x]\n",
       "1               [非梗阻性无精症/x]\n",
       "2         [全部/n, 卵/n, 异常/d]\n",
       "Name: x_cn, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "jieba.load_userdict('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (done)/NLP_for_onedrive/hpo_dict_for_jieba.txt') \n",
    "result= X.apply(lambda txt: list(pseg.cut(txt)))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3215, 1000) Y_train shape: (3215, 455) X_test shape: (1072, 1000) Y_test shape: (1072, 455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Y : One-hot Encoding\n",
    "Y_onehot, num_classes, lables = onehot(Y) # One-hot Encoding\n",
    "#print(lables)\n",
    "#labels = encoder_lab.categories_\n",
    "#labels = encoder_lab.classes_\n",
    "lables.to_csv('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (en cours)/NLP_for_onedrive/In_Database_cn/lables_nn.csv', header=True, index=False, encoding=\"ANSI\")\n",
    "\n",
    "\n",
    "#  Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(\n",
    "    x_cut, Y_onehot, test_size=0.25, random_state=0)\n",
    "#print('x_train shape:', x_train.shape, 'Y_train shape:', Y_train.shape, 'x_test shape:', x_test.shape, 'Y_test shape:', Y_test.shape)\n",
    "\n",
    "\n",
    "# X : BOW\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "vocab_size  = 1000 \n",
    "tokenize = text.Tokenizer(num_words = vocab_size, char_level=False)\n",
    "\n",
    "tokenize.fit_on_texts(x_train) # only fit on train\n",
    "X_train = tokenize.texts_to_matrix(x_train, mode='tfidf')\n",
    "X_test  = tokenize.texts_to_matrix(x_test, mode='tfidf')\n",
    "\n",
    "print('X_train shape:', X_train.shape, 'Y_train shape:', Y_train.shape, 'X_test shape:', X_test.shape, 'Y_test shape:', Y_test.shape)\n",
    "\n",
    "\n",
    "# Increase sample size (in our case do not change evaluation metrics)\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#smote = SMOTE('minority')\n",
    "\n",
    "#X_sm, Y_sm = smote.fit_resample(X_train, Y_train)\n",
    "#print('X_sm shape:', X_sm.shape, 'x_sm shape:', Y_sm.shape)\n",
    "\n",
    "\n",
    "# save tokenizer\n",
    "with open('tokenizer_keras_cn_nn.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenize, handle, protocol=pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter grid for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(num_filters=[32, 64, 128],\n",
    "                  kernel_size=[3, 5, 7],\n",
    "                  vocab_size=[vocab_size],\n",
    "                  embedding_dim=[embedding_dim],\n",
    "                  maxlen=[maxlen])\n",
    "model = KerasClassifier(build_fn=create_model,\n",
    "                        epochs=epochs, batch_size=10,\n",
    "                        verbose=False)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                          cv=4, verbose=1, n_iter=5)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate testing set\n",
    "test_accuracy = grid.score(X_test, y_test)\n",
    "\n",
    "# Save and evaluate results\n",
    "prompt = input(f'finished {source}; write to file and proceed? [y/n]')\n",
    "if prompt.lower() not in {'y', 'true', 'yes'}:\n",
    "    break\n",
    "with open(output_file, 'a') as f:\n",
    "    s = ('Running {} data set\\nBest Accuracy : '\n",
    "         '{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
    "    output_string = s.format(\n",
    "        source,\n",
    "        grid_result.best_score_,\n",
    "        grid_result.best_params_,\n",
    "        test_accuracy)\n",
    "    print(output_string)\n",
    "    f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit sequential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 455)               45955     \n",
      "=================================================================\n",
      "Total params: 146,055\n",
      "Trainable params: 146,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(vocab_size,), activation='relu')) # first hidden layer has 100 nodes, use relu activation\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax')) # second hidden layer has num_classes nodes, use softmax activation\n",
    "# sigmoid for binary classification, or softmax for multi-class classification.\n",
    "model.compile(loss='categorical_crossentropy', # binary_crossentropy; categorical_crossentropy, kullback_leibler_divergence, sparse_categorical_crossentropy (no need of onehot)\n",
    "              optimizer='adam', # gradient descent\n",
    "              metrics=['accuracy']) # Compile Keras Model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3215 samples, validate on 1072 samples\n",
      "Epoch 1/20\n",
      "3215/3215 [==============================] - 0s 84us/step - loss: 5.4710 - accuracy: 0.1309 - val_loss: 4.6855 - val_accuracy: 0.2509\n",
      "Epoch 2/20\n",
      "3215/3215 [==============================] - 0s 64us/step - loss: 3.9897 - accuracy: 0.3067 - val_loss: 3.8888 - val_accuracy: 0.3554\n",
      "Epoch 3/20\n",
      "3215/3215 [==============================] - 0s 61us/step - loss: 3.2517 - accuracy: 0.4093 - val_loss: 3.4334 - val_accuracy: 0.4272\n",
      "Epoch 4/20\n",
      "3215/3215 [==============================] - 0s 60us/step - loss: 2.7199 - accuracy: 0.4936 - val_loss: 3.1024 - val_accuracy: 0.4841\n",
      "Epoch 5/20\n",
      "3215/3215 [==============================] - 0s 56us/step - loss: 2.3082 - accuracy: 0.5729 - val_loss: 2.8485 - val_accuracy: 0.5159\n",
      "Epoch 6/20\n",
      "3215/3215 [==============================] - 0s 62us/step - loss: 1.9625 - accuracy: 0.6348 - val_loss: 2.6341 - val_accuracy: 0.5588\n",
      "Epoch 7/20\n",
      "3215/3215 [==============================] - 0s 52us/step - loss: 1.6816 - accuracy: 0.6961 - val_loss: 2.4506 - val_accuracy: 0.5942\n",
      "Epoch 8/20\n",
      "3215/3215 [==============================] - 0s 51us/step - loss: 1.4390 - accuracy: 0.7325 - val_loss: 2.2980 - val_accuracy: 0.6101\n",
      "Epoch 9/20\n",
      "3215/3215 [==============================] - 0s 57us/step - loss: 1.2339 - accuracy: 0.7695 - val_loss: 2.1708 - val_accuracy: 0.6213\n",
      "Epoch 10/20\n",
      "3215/3215 [==============================] - 0s 50us/step - loss: 1.0937 - accuracy: 0.7851 - val_loss: 2.0709 - val_accuracy: 0.6381\n",
      "Epoch 11/20\n",
      "3215/3215 [==============================] - 0s 54us/step - loss: 0.9599 - accuracy: 0.8162 - val_loss: 2.0022 - val_accuracy: 0.6437\n",
      "Epoch 12/20\n",
      "3215/3215 [==============================] - 0s 62us/step - loss: 0.8567 - accuracy: 0.8302 - val_loss: 1.9475 - val_accuracy: 0.6483\n",
      "Epoch 13/20\n",
      "3215/3215 [==============================] - 0s 52us/step - loss: 0.7876 - accuracy: 0.8445 - val_loss: 1.9148 - val_accuracy: 0.6539\n",
      "Epoch 14/20\n",
      "3215/3215 [==============================] - 0s 65us/step - loss: 0.7024 - accuracy: 0.8566 - val_loss: 1.8960 - val_accuracy: 0.6567\n",
      "Epoch 15/20\n",
      "3215/3215 [==============================] - 0s 54us/step - loss: 0.6546 - accuracy: 0.8628 - val_loss: 1.8739 - val_accuracy: 0.6576\n",
      "Epoch 16/20\n",
      "3215/3215 [==============================] - 0s 56us/step - loss: 0.6110 - accuracy: 0.8706 - val_loss: 1.8600 - val_accuracy: 0.6632\n",
      "Epoch 17/20\n",
      "3215/3215 [==============================] - 0s 65us/step - loss: 0.5620 - accuracy: 0.8812 - val_loss: 1.8612 - val_accuracy: 0.6614\n",
      "Epoch 18/20\n",
      "3215/3215 [==============================] - 0s 48us/step - loss: 0.5315 - accuracy: 0.8883 - val_loss: 1.8525 - val_accuracy: 0.6698\n",
      "Epoch 19/20\n",
      "3215/3215 [==============================] - 0s 49us/step - loss: 0.5014 - accuracy: 0.8902 - val_loss: 1.8673 - val_accuracy: 0.6679\n",
      "Epoch 20/20\n",
      "3215/3215 [==============================] - 0s 48us/step - loss: 0.4796 - accuracy: 0.8989 - val_loss: 1.8773 - val_accuracy: 0.6707\n",
      "Training Accuracy: 0.9378\n",
      "Testing Accuracy:  0.6707\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    #X_sm, Y_sm,\n",
    "                    epochs=20,      # One pass through all of the rows in the training dataset\n",
    "                    verbose=1,        # show training process\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    batch_size= 50)   # One or more samples considered by the model within an epoch before weights are updated\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "#plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([X_test[i]]))\n",
    "    predicted_label = pd.DataFrame(lables)[np.argmax(prediction)]\n",
    "    print('Actual label   :', Y_test[i])\n",
    "    print('Predicted label:', Y_test[i])\n",
    "    print(\"Predicted label: \", predicted_label,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (en cours)/NLP_for_onedrive/In_Database_cn/M_bow_neuralnetwork_cn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 459)               46359     \n",
      "=================================================================\n",
      "Total params: 146,459\n",
      "Trainable params: 146,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "model = tf.keras.models.load_model('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (en cours)/NLP_for_onedrive/In_Database_cn/M_bow_neuralnetwork_cn.h5') # or Conv1D_model.h5\n",
    "print('Load model...')\n",
    "model.summary()\n",
    "\n",
    "with open('tokenizer_keras_CN_nn.pickle', 'rb') as handle:\n",
    "    loaded_tokenizer = pickle.load(handle)\n",
    "    \n",
    "lables = pd.read_csv('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (en cours)/NLP_for_onedrive/In_Database_cn/lables_nn.csv', encoding=\"ANSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jingz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Jingz\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Jingz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Jingz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# res = pd.DataFrame({'X':X, 'real_lable': Y})\n",
    "Df['pred_lable_nn'] = Df['pred_hp_nn'] = Df['same'] = Df.index.values\n",
    "\n",
    "for l in range(0,len(X)):\n",
    "    i = X.index.values[l]\n",
    "    txt = list(jieba.cut(X[i]))\n",
    "    txt = loaded_tokenizer.texts_to_matrix([txt], mode='tfidf')\n",
    "    pred = model.predict_classes(txt)\n",
    "    pred_lab = lables.loc[lables['y_id']==pred[0]]['y_labels'].reset_index(drop=True)[0]\n",
    "    pred_hp = lables.loc[lables['y_id']==pred[0]]['y_labels'].reset_index(drop=True)[0]\n",
    "    Df['pred_lable_nn'][i] = pred_lab\n",
    "\n",
    "    if Df['y_cn'][i]==Df['pred_lable_nn'][i]:\n",
    "        Df['same'][i] = 1\n",
    "    else :\n",
    "        Df['same'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.880597\n",
      "Precision_macro: 0.903785\n",
      "Recall_macro: 0.880597\n",
      "F1 score_macro: 0.881450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jingz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Df.y_cn, Df.pred_lable_nn)\n",
    "print('Accuracy: %f' % accuracy)  # same \n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Df.y_cn, Df.pred_lable_nn, average='weighted') # take into account for label imbalance\n",
    "print('Precision_macro: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Df.y_cn, Df.pred_lable_nn, average='weighted')\n",
    "print('Recall_macro: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Df.y_cn, Df.pred_lable_nn, average='weighted')\n",
    "print('F1 score_macro: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df.to_csv('C://Users/Jingz/OneDrive/CarrierGene/2019.07.10-HPO (en cours)/NLP_for_onedrive/Run/prediction_nn.csv', header=True, index=False, encoding=\"ANSI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
